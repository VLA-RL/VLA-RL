{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rlbench.action_modes.action_mode import MoveArmThenGripper\n",
    "from rlbench.action_modes.arm_action_modes import ArmActionMode, JointVelocity, JointPosition, EndEffectorPoseViaPlanning, EndEffectorPoseViaIK\n",
    "\n",
    "\n",
    "from rlbench.action_modes.gripper_action_modes import Discrete\n",
    "from rlbench.environment import Environment\n",
    "from rlbench.observation_config import ObservationConfig, CameraConfig\n",
    "# from rlbench.tasks.pick_described_object import PickDescribedObject\n",
    "from rlbench.tasks import PutGroceriesInCupboard, PickAndLift, StackBlocks, PlaceHangerOnRack, PickDescribedObject, TakeLidOffSaucepan, SetTheTable\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from matplotlib import pyplot as plt\n",
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROCERY_NAMES = [\n",
    "    \"chocolate jello\",\n",
    "    \"soup\",\n",
    "    \"spam\",\n",
    "    \"mustard\",\n",
    "    \"sugar\",\n",
    "]\n",
    "\n",
    "reasoning = [\n",
    "    \"Gripper haven't grasped the {item}\",\n",
    "    \"Gripper grasped the {item}, but it is not in the basket\",\n",
    "    \"Gripper grasped the {item} and it is above the basket\",\n",
    "]\n",
    "steps = [\n",
    "    \"Move to the {item} and pick it up.\",\n",
    "    \"Move over the basket.\",\n",
    "    \"Move down and place the {item} in the basket.\",\n",
    "]\n",
    "subtasks = [\n",
    "    \"1.Move to the {item} and pick it up. 2.Move over the basket. 3.Place the {item} in the basket.\",\n",
    "    \"1.Move over the basket. 2.Place the {item} in the basket.\",\n",
    "    \"\"\n",
    "]\n",
    "prompt = \"\"\"\n",
    "{item} POSE: {target_item_pose}\n",
    "BASKET POSE: {basket_position}\n",
    "GRIPPER POSE: {gripper_pose}\n",
    "REASONING: {REASONING}\n",
    "SUBTASKS: {SUBTASKS}\n",
    "CURRENT STEP: {STEP}\n",
    "ACTION: {action}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(task, variation_num):\n",
    "    target_item_poses = []\n",
    "    waypoints = []\n",
    "    gripper_poses = []\n",
    "    front_rgbs = []\n",
    "\n",
    "    def callable_fun(obs, task, variation_num):\n",
    "        # target item pose\n",
    "        target_item_pose = task._task.get_graspable_objects()[variation_num].get_pose()\n",
    "        target_item_pose = np.concatenate([target_item_pose[:3], R.from_quat(target_item_pose[3:]).as_euler('xyz')])\n",
    "        target_item_poses.append(target_item_pose)\n",
    "\n",
    "        #waypoints\n",
    "        current_pose = obs.gripper_pose\n",
    "        current_pose = np.concatenate([current_pose[:3], R.from_quat(current_pose[3:]).as_euler('xyz')])\n",
    "        gripper_poses.append(np.concatenate([current_pose, [obs.gripper_open]]))\n",
    "        wps = [wp._waypoint.get_position() for wp in task._task._waypoints]\n",
    "        \n",
    "        if abs(current_pose[:3] - wps[0]).mean() < 1e-1:\n",
    "            waypoints.append(0)\n",
    "        elif abs(current_pose[:3] - wps[1]).mean() < 1e-2:\n",
    "            waypoints.append(1)\n",
    "        elif abs(current_pose[:3] - wps[2]).mean() < 1e-2:\n",
    "            waypoints.append(2)\n",
    "        else:\n",
    "            waypoints.append(-1)\n",
    "\n",
    "        #front rgb\n",
    "        front_rgbs.append(obs.front_rgb)\n",
    "\n",
    "    task.reset()\n",
    "    _ = task._scene.get_demo(callable_each_step=lambda obs: callable_fun(obs,task=task, variation_num=variation_num)) \n",
    "    basket_position = task._task.dropin_box.get_position()\n",
    "\n",
    "    id_0 = int(np.where(np.array(waypoints) == 0)[0].mean())\n",
    "    id_1 = int(np.where(np.array(waypoints) == 1)[0].mean())\n",
    "    id_2 = int(np.where(np.array(waypoints) == 2)[0].mean())\n",
    "\n",
    "    keyframe = lambda a,b, c, gap: [(a-(i+1)*gap, a, c) for i in range((a - b)//gap)]\n",
    "\n",
    "    keyframes = keyframe(id_0, 0, 0, 8) + keyframe(id_1, id_0, 1, 8) + keyframe(id_2, id_1,  2, 8)\n",
    "\n",
    "    imgs = []\n",
    "    instruction = \"pick up the %s and place in the basket\" % GROCERY_NAMES[variation_num]\n",
    "    instructions = []\n",
    "    cots = []\n",
    "    target_item_poses_ = []\n",
    "    gripper_poses_ = []\n",
    "    basket_positions_ = []\n",
    "    actions = []\n",
    "\n",
    "    for cur_id, key_id, step in keyframes:\n",
    "        item = GROCERY_NAMES[variation_num]\n",
    "        inputs = prompt.format(item = item,\n",
    "                    target_item_pose = \"{target_item_pose}\",\n",
    "                    basket_position = \"{basket_position}\",\n",
    "                    gripper_pose = \"{gripper_pose}\",\n",
    "                    REASONING = reasoning[step].format(item=item),   \n",
    "                    STEP = steps[step].format(item=item),\n",
    "                    SUBTASKS = subtasks[0].format(item=item),\n",
    "                    action = \"{action}\")\n",
    "        imgs.append(front_rgbs[cur_id])\n",
    "        instructions.append(instruction)\n",
    "        cots.append(inputs)\n",
    "        target_item_poses_.append(target_item_poses[cur_id])\n",
    "        gripper_poses_.append(gripper_poses[cur_id])\n",
    "        basket_positions_.append(basket_position)\n",
    "        actions.append(gripper_poses[key_id])\n",
    "    return imgs, instructions, cots, target_item_poses_, gripper_poses_, basket_positions_, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to be executed in each process\n",
    "def process_variation(i, task, manager_dict, lock):\n",
    "    local_train_imgs = []\n",
    "    local_train_instructions = []\n",
    "    local_train_cots = []\n",
    "    local_train_target_item_poses = []\n",
    "    local_train_gripper_poses = []\n",
    "    local_train_basket_positions = []\n",
    "    local_train_actions = []\n",
    "\n",
    "    local_test_imgs = []\n",
    "    local_test_instructions = []\n",
    "    local_test_cots = []\n",
    "    local_test_target_item_poses = []\n",
    "    local_test_gripper_poses = []\n",
    "    local_test_basket_positions = []\n",
    "    local_test_actions = []\n",
    "\n",
    "    camera = CameraConfig(image_size=(224, 224), depth=False, point_cloud=False, mask=False)\n",
    "    obs_config = ObservationConfig(left_shoulder_camera=camera, right_shoulder_camera=camera, front_camera=camera, overhead_camera=camera)\n",
    "\n",
    "    env = Environment(\n",
    "        action_mode=MoveArmThenGripper(\n",
    "            arm_action_mode=EndEffectorPoseViaPlanning(absolute_mode=True, collision_checking=True), gripper_action_mode=Discrete()),\n",
    "        obs_config=obs_config,\n",
    "        headless=True)\n",
    "    env.launch()\n",
    "    task = env.get_task(PickDescribedObject)\n",
    "    task.set_variation(i)\n",
    "\n",
    "    j = 0\n",
    "    while j < 10:\n",
    "        try:\n",
    "            imgs, instructions, cots, target_item_poses, gripper_poses, basket_positions, actions = run_episode(task, i)\n",
    "            j += 1\n",
    "            print(f\"variation{i}, epoisode{j} done\")\n",
    "            if j < 8:\n",
    "                local_train_imgs += imgs\n",
    "                local_train_instructions += instructions\n",
    "                local_train_cots += cots\n",
    "                local_train_target_item_poses += target_item_poses\n",
    "                local_train_gripper_poses += gripper_poses\n",
    "                local_train_basket_positions += basket_positions\n",
    "                local_train_actions += actions\n",
    "            else:\n",
    "                local_test_imgs += imgs\n",
    "                local_test_instructions += instructions\n",
    "                local_test_cots += cots\n",
    "                local_test_target_item_poses += target_item_poses\n",
    "                local_test_gripper_poses += gripper_poses\n",
    "                local_test_basket_positions += basket_positions\n",
    "                local_test_actions += actions\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    with lock:\n",
    "        manager_dict['train_imgs'] += local_train_imgs\n",
    "        manager_dict['train_instructions'] += local_train_instructions\n",
    "        manager_dict['train_cots'] += local_train_cots\n",
    "        manager_dict['train_target_item_poses'] += local_train_target_item_poses\n",
    "        manager_dict['train_gripper_poses'] += local_train_gripper_poses\n",
    "        manager_dict['train_basket_positions'] += local_train_basket_positions\n",
    "        manager_dict['train_actions'] += local_train_actions\n",
    "\n",
    "        manager_dict['test_imgs'] += local_test_imgs\n",
    "        manager_dict['test_instructions'] += local_test_instructions\n",
    "        manager_dict['test_cots'] += local_test_cots\n",
    "        manager_dict['test_target_item_poses'] += local_test_target_item_poses\n",
    "        manager_dict['test_gripper_poses'] += local_test_gripper_poses\n",
    "        manager_dict['test_basket_positions'] += local_test_basket_positions\n",
    "        manager_dict['test_actions'] += local_test_actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "lock = manager.Lock()\n",
    "\n",
    "# Create shared lists\n",
    "manager_dict = manager.dict({\n",
    "    'train_imgs': [],\n",
    "    'train_instructions': [],\n",
    "    'train_cots': [],\n",
    "    'train_target_item_poses': [],\n",
    "    'train_gripper_poses': [],\n",
    "    'train_basket_positions': [],\n",
    "    'train_actions': [],\n",
    "    'test_imgs': [],\n",
    "    'test_instructions': [],\n",
    "    'test_cots': [],\n",
    "    'test_target_item_poses': [],\n",
    "    'test_gripper_poses': [],\n",
    "    'test_basket_positions': [],\n",
    "    'test_actions': []\n",
    "})\n",
    "\n",
    "task = env.get_task(PickDescribedObject)\n",
    "\n",
    "processes = []\n",
    "for i in range(5):\n",
    "    p = multiprocessing.Process(target=process_variation, args=(i, task, manager_dict, lock))\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print('Data collection done!')\n",
    "print(manager_dict['train_imgs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'imgs': manager_dict['train_imgs'],\n",
    "    'instructions': manager_dict['train_instructions'],\n",
    "    'cots': manager_dict['train_cots'],\n",
    "    'target_item_poses': manager_dict['train_target_item_poses'],\n",
    "    'gripper_poses': manager_dict['train_gripper_poses'],\n",
    "    'basket_positions': manager_dict['train_basket_positions'],\n",
    "    'actions': manager_dict['train_actions']\n",
    "}\n",
    "test_data = {\n",
    "    'imgs': manager_dict['test_imgs'],\n",
    "    'instructions': manager_dict['test_instructions'],\n",
    "    'cots': manager_dict['test_cots'],\n",
    "    'target_item_poses': manager_dict['test_target_item_poses'],\n",
    "    'gripper_poses': manager_dict['test_gripper_poses'],\n",
    "    'basket_positions': manager_dict['test_basket_positions'],\n",
    "    'actions': manager_dict['test_actions']\n",
    "}\n",
    "\n",
    "torch.save(train_data, './datasets/pick_described_object/train.pt')\n",
    "torch.save(test_data, './datasets/pick_described_object/test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLA-RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
