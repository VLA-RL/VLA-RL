{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 06:18:20.221255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 06:18:20.221307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 06:18:20.229353: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 06:18:20.237053: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 06:18:21.460153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import draccus\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import tqdm\n",
    "import wandb\n",
    "from accelerate import PartialState\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "from vla.base_prompter import PurePromptBuilder\n",
    "from vla.utils import PaddedCollatorForPosePrediction, runningLoss, SamplerForPosePrediction\n",
    "from vla.action_tokenizer import RLbenchPoseTokenizer\n",
    "from vla.dataset import RLbenchCotDataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FinetuneConfig:\n",
    "    # fmt: off\n",
    "    vla_path: str = \"/media/lawrence/Work/checkpoints/ecot-openvla-7b-bridge\"   # Path to OpenVLA model \n",
    "    vla_path_q: str = \"/media/lawrence/Work/checkpoints/ecot-openvla-7b-bridge-4b\"   # Path to OpenVLA model\n",
    "\n",
    "    experiment_name: str = \"weighted_loss_cot_\"\n",
    "    dataset_name: str = \"pick_described_object_replay\"                                # Name of fine-tuning dataset (e.g., `droid_wipe`)\n",
    "    # data_path: Path = Path(f\"./datasets/{dataset_name}/data.pt\")\n",
    "    train_data_path: Path = Path(f\"./datasets/{dataset_name}/data.pt\")\n",
    "    # test_data_path: Path = Path(f\"./datasets/{dataset_name}/test_data.pt\")\n",
    "    item_num = 5\n",
    "    stage_num = 2\n",
    "    run_root_dir: Path = Path(\"./runs\")                               # Path to directory to store logs & checkpoints\n",
    "    adapter_dir: Path = Path(\"./adapter-tmp\")                     # Temporary directory for LoRA weights before fusing\n",
    "\n",
    "    # Fine-tuning Parameters\n",
    "    seed: int = 42                                                  # Random seed\n",
    "    episode: int = 2\n",
    "    batch_size: int = 2#16                                            # Fine-tuning batch size\n",
    "    test_limit_length: int = 30\n",
    "    save_steps: int = 20#5000                                          # Interval for checkpoint saving\n",
    "    learning_rate: float = 5e-5                                     # Fine-tuning learning rate\n",
    "    weight_decay: float = 0.01                                      # Fine-tuning weight decay\n",
    "    grad_accumulation_steps: int = 10                                # Gradient accumulation steps\n",
    "\n",
    "    # LoRA Arguments\n",
    "    use_lora: bool = True                                           # Whether to use LoRA fine-tuning\n",
    "    lora_rank: int = 16#32                                             # Rank of LoRA weight matrix\n",
    "    lora_dropout: float = 0.0                                       # Dropout applied to LoRA weights\n",
    "    use_quantization: bool = True                                  # Whether to 4-bit quantize VLA for LoRA fine-tuning\n",
    "                                                                    #   => CAUTION: Reduces memory but hurts performance\n",
    "    dataset_statistics: tuple = (np.array([-0.2, -0.35,  0.75199986, -np.pi/2, -np.pi/2, -np.pi/2,  0. ]), np.array([0.5, 0.35, 1.3, np.pi/2, 0, np.pi/2, 1.])) # Min-Max normalization statistics\n",
    "\n",
    "    # Tracking Parameters\n",
    "    wandb_project: str = \"vla-rl\"                                  # Name of W&B project to log to (use default!)\n",
    "    wandb_entity: str = \"lawrence-rs-lin-university-of-toronto\"                           # Name of entity to log under\n",
    "\n",
    "    # fmt: on\n",
    "cfg = FinetuneConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning OpenVLA Model `/media/lawrence/Work/checkpoints/ecot-openvla-7b-bridge` on `pick_described_object_replay`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d5bcb7544147208d9634b9cd85c57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Fine-tuning OpenVLA Model `{cfg.vla_path}` on `{cfg.dataset_name}`\")\n",
    "\n",
    "# [Validate] Ensure GPU Available & Set Device / Distributed Context\n",
    "assert torch.cuda.is_available(), \"Fine-tuning assumes at least one GPU is available!\"\n",
    "distributed_state = PartialState()\n",
    "torch.cuda.set_device(device_id := distributed_state.local_process_index)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Configure Unique Experiment ID & Log Directory\n",
    "exp_id = (\n",
    "    f\"{cfg.vla_path.split('/')[-1]}+{cfg.dataset_name}\"\n",
    "    f\"+b{cfg.batch_size * cfg.grad_accumulation_steps}\"\n",
    "    f\"+lr-{cfg.learning_rate}\"\n",
    ")\n",
    "if cfg.use_lora:\n",
    "    exp_id += f\"+lora-r{cfg.lora_rank}+dropout-{cfg.lora_dropout}\"\n",
    "if cfg.use_quantization:\n",
    "    exp_id += \"+q-4bit\"\n",
    "\n",
    "# Start =>> Build Directories\n",
    "run_dir, adapter_dir = cfg.run_root_dir / exp_id, cfg.adapter_dir / exp_id\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# Quantization Config =>> only if LoRA fine-tuning\n",
    "quantization_config = None\n",
    "if cfg.use_quantization:\n",
    "    assert cfg.use_lora, \"Quantized training only supported for LoRA fine-tuning!\"\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_quant_type=\"nf4\", #llm_int8_skip_modules = ['projector'],\n",
    "    )\n",
    "\n",
    "# Load OpenVLA Processor and Model using HF AutoClasses\n",
    "processor = AutoProcessor.from_pretrained(cfg.vla_path, trust_remote_code=True)\n",
    "add_tokens = ['<g>', '</g>'] + [f'<item_{i}>' for i in np.arange(cfg.item_num)] + ['<o>', '</o>', '<t>', '</t>'] + [f'<stage_{i}>' for i in np.arange(cfg.stage_num)] + ['<a>', '</a>', '<q>', '<cot>']\n",
    "processor.tokenizer.add_tokens(add_tokens)\n",
    "vla = AutoModelForVision2Seq.from_pretrained(\n",
    "    cfg.vla_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    quantization_config=quantization_config,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map = \"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenVLAForActionPrediction(\n",
       "  (vision_backbone): PrismaticVisionBackbone(\n",
       "    (featurizer): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (24): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (25): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (26): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn_pool): AttentionPoolLatent(\n",
       "        (q): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "        (kv): Linear4bit(in_features=1152, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Identity()\n",
       "    )\n",
       "  )\n",
       "  (projector): PrismaticProjector(\n",
       "    (fc1): Linear4bit(in_features=1152, out_features=4096, bias=True)\n",
       "    (fc2): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
       "    (act_fn1): GELU(approximate='none')\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 48,801,984 || all params: 7,236,926,592 || trainable%: 0.6743\n"
     ]
    }
   ],
   "source": [
    "# Device Placement =>> note that BitsAndBytes automatically handles for quantized training\n",
    "if cfg.use_quantization:\n",
    "    vla = prepare_model_for_kbit_training(vla)\n",
    "else:\n",
    "    vla = vla.to(device_id)\n",
    "\n",
    "# [LoRA] Wrap Model w/ PEFT `LoraConfig` =>> by default we set `target_modules=all-linear`\n",
    "if cfg.use_lora:\n",
    "    lora_config = LoraConfig(\n",
    "        r=cfg.lora_rank,\n",
    "        lora_alpha=min(cfg.lora_rank, 16),\n",
    "        lora_dropout=cfg.lora_dropout,\n",
    "        target_modules=\"all-linear\",\n",
    "        init_lora_weights=\"gaussian\",\n",
    "    )\n",
    "    vla = get_peft_model(vla, lora_config)\n",
    "    vla.print_trainable_parameters()\n",
    "\n",
    "# # Wrap VLA in PyTorch DDP Wrapper for Multi-GPU Training\n",
    "# vla = DDP(vla, device_ids=[device_id], find_unused_parameters=True, gradient_as_bucket_view=True)\n",
    "\n",
    "# Create Optimizer =>> note that we default to a simple constant learning rate!\n",
    "trainable_params = [param for param in vla.parameters() if param.requires_grad]\n",
    "optimizer = AdamW(trainable_params, lr=cfg.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Action Tokenizer\n",
    "action_tokenizer = RLbenchPoseTokenizer(processor.tokenizer, cfg.dataset_statistics)\n",
    "\n",
    "trainset = RLbenchCotDataset(\n",
    "    cfg.train_data_path,\n",
    "    action_tokenizer,\n",
    "    processor.tokenizer,\n",
    "    image_transform=processor.image_processor.apply_transform,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "# Create Collator and DataLoader\n",
    "collator = PaddedCollatorForPosePrediction(\n",
    "    processor.tokenizer.model_max_length, processor.tokenizer.pad_token_id, padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# train_sampler = SamplerForPosePrediction(np.array(trainset.data['stages']),group1_ratio=0.3)\n",
    "# test_sampler = SamplerForPosePrediction(np.array(testset.data['stages']),group1_ratio=0.3)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    # sampler=train_sampler,\n",
    "    collate_fn=collator,\n",
    "    num_workers=1,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    collate_fn=collator,\n",
    "    num_workers=1,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[-0.9608, -0.9765, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-0.9608, -0.9843, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-0.9765, -0.9843, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [ 0.5765,  0.5451,  0.5529,  ...,  0.4980,  0.5686,  0.6235],\n",
       "           [ 0.5765,  0.5686,  0.5922,  ...,  0.5529,  0.5373,  0.5843],\n",
       "           [ 0.6157,  0.6157,  0.6392,  ...,  0.6157,  0.5451,  0.5843]],\n",
       " \n",
       "          [[-0.5608, -0.5765, -0.6000,  ..., -0.5843, -0.5686, -0.5686],\n",
       "           [-0.5608, -0.5843, -0.6000,  ..., -0.5843, -0.5686, -0.5686],\n",
       "           [-0.5765, -0.5843, -0.6000,  ..., -0.5843, -0.5686, -0.5686],\n",
       "           ...,\n",
       "           [ 0.2392,  0.2078,  0.2157,  ...,  0.2157,  0.2863,  0.3412],\n",
       "           [ 0.2392,  0.2314,  0.2549,  ...,  0.2706,  0.2549,  0.3020],\n",
       "           [ 0.2784,  0.2784,  0.3020,  ...,  0.3333,  0.2627,  0.3020]],\n",
       " \n",
       "          [[-0.5294, -0.5451, -0.5686,  ..., -0.5529, -0.5451, -0.5451],\n",
       "           [-0.5294, -0.5529, -0.5686,  ..., -0.5529, -0.5451, -0.5451],\n",
       "           [-0.5451, -0.5529, -0.5686,  ..., -0.5529, -0.5451, -0.5451],\n",
       "           ...,\n",
       "           [-0.3804, -0.4118, -0.4039,  ..., -0.3804, -0.3098, -0.2549],\n",
       "           [-0.3804, -0.3882, -0.3647,  ..., -0.3255, -0.3412, -0.2941],\n",
       "           [-0.3412, -0.3412, -0.3176,  ..., -0.2627, -0.3333, -0.2941]]],\n",
       " \n",
       " \n",
       "         [[[-0.9608, -0.9765, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-0.9608, -0.9843, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-0.9765, -0.9843, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [ 0.5529,  0.5216,  0.5451,  ...,  0.4980,  0.5686,  0.6235],\n",
       "           [ 0.5451,  0.5451,  0.5686,  ...,  0.5529,  0.5373,  0.5843],\n",
       "           [ 0.5843,  0.5922,  0.6157,  ...,  0.6157,  0.5451,  0.5843]],\n",
       " \n",
       "          [[-0.5608, -0.5765, -0.6000,  ..., -0.5843, -0.5686, -0.5686],\n",
       "           [-0.5608, -0.5843, -0.6000,  ..., -0.5843, -0.5686, -0.5686],\n",
       "           [-0.5765, -0.5843, -0.6000,  ..., -0.5843, -0.5686, -0.5686],\n",
       "           ...,\n",
       "           [ 0.2549,  0.2235,  0.2235,  ...,  0.2157,  0.2863,  0.3412],\n",
       "           [ 0.2549,  0.2471,  0.2706,  ...,  0.2706,  0.2549,  0.3020],\n",
       "           [ 0.2941,  0.2941,  0.3176,  ...,  0.3333,  0.2627,  0.3020]],\n",
       " \n",
       "          [[-0.5294, -0.5451, -0.5686,  ..., -0.5529, -0.5451, -0.5451],\n",
       "           [-0.5294, -0.5529, -0.5686,  ..., -0.5529, -0.5451, -0.5451],\n",
       "           [-0.5451, -0.5529, -0.5686,  ..., -0.5529, -0.5451, -0.5451],\n",
       "           ...,\n",
       "           [-0.3804, -0.4118, -0.4039,  ..., -0.3804, -0.3098, -0.2549],\n",
       "           [-0.3804, -0.3882, -0.3647,  ..., -0.3255, -0.3412, -0.2941],\n",
       "           [-0.3412, -0.3412, -0.3176,  ..., -0.2627, -0.3333, -0.2941]]]]),\n",
       " 'input_ids': tensor([[    1,   512, 29901,  1724,   881,   367,   278,  2446,  1820, 18593,\n",
       "            310,   278,   330,   374,  2496,   304,  3787,   278,   805,   314,\n",
       "            508,   297,   278, 25972, 29973,   450,  1857,   330,   374,  2496,\n",
       "          18593,   338, 32001, 31444, 31498, 31609, 31747, 31897, 31997, 31998,\n",
       "          32002, 29889,    13,  4451, 29901, 32017, 32005, 29892, 32008, 31447,\n",
       "          31498, 31604, 32009, 29892, 32010, 31398, 31501, 31643, 32011, 29892,\n",
       "          32013, 29892, 32014, 31398, 31501, 31679, 31747, 31897, 31997, 31999,\n",
       "          32015, 29892, 32016, 32000,     2],\n",
       "         [    1,   512, 29901,  1724,   881,   367,   278,  2446,  1820, 18593,\n",
       "            310,   278,   330,   374,  2496,   304,  1925,   278,   508,  9571,\n",
       "          22300,   297,   278, 25972, 29973,   450,  1857,   330,   374,  2496,\n",
       "          18593,   338, 32001, 31488, 31586, 31657, 31754, 31871, 31927, 31999,\n",
       "          32002, 29889,    13,  4451, 29901, 32017, 32004, 29892, 32008, 31450,\n",
       "          31590, 31606, 32009, 29892, 32010, 31398, 31501, 31643, 32011, 29892,\n",
       "          32012, 29892, 32014, 31450, 31590, 31611, 31747, 31897, 31964, 31998,\n",
       "          32015, 29892, 32016, 32000,     2]]),\n",
       " 'attention_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False,  True]]),\n",
       " 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100, 32005, 29892, 32008, 31447,\n",
       "          31498, 31604, 32009, 29892, 32010, 31398, 31501, 31643, 32011, 29892,\n",
       "          32013, 29892, 32014, 31398, 31501, 31679, 31747, 31897, 31997, 31999,\n",
       "          32015, 29892, 32016,  -100,     2],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100, 32004, 29892, 32008, 31450,\n",
       "          31590, 31606, 32009, 29892, 32010, 31398, 31501, 31643, 32011, 29892,\n",
       "          32012, 29892, 32014, 31450, 31590, 31611, 31747, 31897, 31964, 31998,\n",
       "          32015, 29892, 32016,  -100,     2]]),\n",
       " 'grippers': tensor([[ 1.2406e-01, -3.7688e-01,  8.1527e-01,  3.1410e+00,  7.2659e-04,\n",
       "           2.6369e+00,  0.0000e+00],\n",
       "         [ 4.3332e-01,  2.6961e-01,  1.0792e+00, -2.9279e+00, -4.1741e-01,\n",
       "          -6.3552e-01,  1.0000e+00]], dtype=torch.float64),\n",
       " 'items': tensor([2, 1]),\n",
       " 'objects': tensor([[ 0.1453, -0.3895,  0.7900],\n",
       "         [ 0.1683,  0.2977,  0.8000]], dtype=torch.float64),\n",
       " 'targets': tensor([[-0.2000, -0.3250,  1.0000],\n",
       "         [-0.2000, -0.3250,  1.0000]], dtype=torch.float64),\n",
       " 'stages': tensor([1, 0]),\n",
       " 'actions': tensor([[-2.0000e-01, -3.2500e-01,  1.2000e+00,  3.1416e+00, -1.3101e-14,\n",
       "           3.1416e+00,  1.0000e+00],\n",
       "         [ 1.6829e-01,  2.9774e-01,  8.2499e-01,  3.1412e+00, -1.4278e-04,\n",
       "           5.0917e-01,  0.0000e+00]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_running_loss = runningLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vla.train()\n",
    "vla.gradient_checkpointing_enable()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "step_idx, batch = next(enumerate(train_dataloader))\n",
    "\n",
    "with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    vla.train()\n",
    "    output: CausalLMOutputWithPast = vla(\n",
    "        input_ids=batch[\"input_ids\"].to(device_id),\n",
    "        attention_mask=batch[\"attention_mask\"].to(device_id),\n",
    "        pixel_values=batch[\"pixel_values\"].to(torch.bfloat16).to(device_id),\n",
    "        labels=batch[\"labels\"],\n",
    "        use_cache=False\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 32004,\n",
       "         29892, 32008,  -100,  -100,  -100, 32009, 29892, 32010, 31398, 31501,\n",
       "         31643, 32011, 29892, 32013, 29892, 32014,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100, 31999, 32015, 29892, 32016,  -100,     2],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 32003,\n",
       "         29892, 32008,  -100,  -100,  -100, 32009, 29892, 32010, 31398, 31501,\n",
       "         31643, 32011, 29892, 32012, 29892, 32014,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100, 31998, 32015, 29892, 32016,  -100,     2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> In: What should be the next key pose of the gripper to put the spam can in the basket? The current gripper pose is<g>港－局안ḳὀ弘</g>.\\n Out:<cot><item_2>,<o>任세漢</o>,<t>交ペམ</t>,<stage_1>,<a>交ペ电면ḳ收给</a>,<q><PAD></s><PAD><PAD>',\n",
       " '<s> In: What should be the next key pose of the gripper to put the chocolate gelatin in the basket? The current gripper pose is<g>没민奈ṯ∇昭给</g>.\\n Out:<cot><item_0>,<o>计支関</o>,<t>交ペམ</t>,<stage_0>,<a>序拉共면ḳ收弘</a>,<q><PAD></s>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.batch_decode(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (0) to match target batch_size (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_start_idx \u001b[38;5;241m=\u001b[39m vla\u001b[38;5;241m.\u001b[39mvision_backbone\u001b[38;5;241m.\u001b[39mfeaturizer\u001b[38;5;241m.\u001b[39mpatch_embed\u001b[38;5;241m.\u001b[39mnum_patches\n\u001b[0;32m----> 2\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m action_tokenizer\u001b[38;5;241m.\u001b[39mget_loss(output, batch, output_start_idx)\n\u001b[1;32m      3\u001b[0m normalized_loss_dict \u001b[38;5;241m=\u001b[39m train_running_loss\u001b[38;5;241m.\u001b[39mupdate(loss_dict \u001b[38;5;241m=\u001b[39m loss_dict)\n",
      "File \u001b[0;32m~/VLA-RL/VLA-RL/vla/action_tokenizer.py:222\u001b[0m, in \u001b[0;36mRLbenchPoseTokenizer.get_loss\u001b[0;34m(self, output, batch, output_start_idx)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m#Gripper Loss\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# pred_gripper = self.decode(gripper_logits, soft = True)\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# assert pred_gripper.shape == gt_gripper.shape, f\"Gripper shape {pred_gripper.shape} != {gt_gripper.shape}\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m#Item Loss\u001b[39;00m\n\u001b[1;32m    221\u001b[0m gt_item \u001b[38;5;241m=\u001b[39m gt_item\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m--> 222\u001b[0m item_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(item_logits, gt_item)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m#Object Loss\u001b[39;00m\n\u001b[1;32m    225\u001b[0m pred_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(object_logits, soft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (0) to match target batch_size (2)."
     ]
    }
   ],
   "source": [
    "output_start_idx = vla.vision_backbone.featurizer.patch_embed.num_patches\n",
    "loss_dict = action_tokenizer.get_loss(output, batch, output_start_idx)\n",
    "normalized_loss_dict = train_running_loss.update(loss_dict = loss_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nll_loss': tensor(19.6134, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " 'item_loss': tensor(2.9242, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " 'object_position_loss': tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " 'target_position_loss': tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " 'stage_loss': tensor(2.2828, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " 'action_position_loss': tensor(0.0714, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " 'action_orientation_loss': tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'action_open_loss': tensor(3.8399, device='cuda:0', grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nll_loss = output.loss\n",
    "output_logits = output.logits[:, 256:-1]\n",
    "device_id = output_logits.device\n",
    "batch_size = output_logits.size(0)\n",
    "output_gt = batch[\"labels\"][:, 1:].to(device_id)\n",
    "gripper_mask, item_mask, object_mask, target_mask, stage_mask, action_mask = action_tokenizer.get_mask(output_gt)\n",
    "\n",
    "gripper_logits = output_logits[gripper_mask][:,action_tokenizer.action_token_begin_idx:action_tokenizer.tokenizer.vocab_size].view(batch_size,-1,action_tokenizer.n_bins)\n",
    "item_logits = output_logits[item_mask][:,32003:32008]\n",
    "object_logits = output_logits[object_mask][:,action_tokenizer.action_token_begin_idx:action_tokenizer.tokenizer.vocab_size].view(batch_size,-1,action_tokenizer.n_bins)\n",
    "target_logits = output_logits[target_mask][:,action_tokenizer.action_token_begin_idx:action_tokenizer.tokenizer.vocab_size].view(batch_size,-1,action_tokenizer.n_bins)\n",
    "stage_logits = output_logits[stage_mask][:,32012:32014]\n",
    "action_logits = output_logits[action_mask][:,action_tokenizer.action_token_begin_idx:action_tokenizer.tokenizer.vocab_size].view(batch_size,-1,action_tokenizer.n_bins)\n",
    "\n",
    "gt_gripper = batch['grippers'].to(device_id)\n",
    "gt_item = batch['items'].to(device_id)\n",
    "gt_object = batch['objects'].to(device_id)\n",
    "gt_target = batch['targets'].to(device_id)\n",
    "gt_stage = batch['stages'].to(device_id)\n",
    "gt_action = batch['actions'].to(device_id)\n",
    "\n",
    "#Gripper Loss\n",
    "pred_gripper = action_tokenizer.decode(gripper_logits, soft = True)\n",
    "assert pred_gripper.shape == gt_gripper.shape, f\"Gripper shape {pred_gripper.shape} != {gt_gripper.shape}\"\n",
    "gripper_position_loss = F.mse_loss(pred_gripper[:,:3], gt_gripper[:,:3].to(torch.float32))\n",
    "gripper_orientation_loss = action_tokenizer.angle_loss(pred_gripper[:,3:6], gt_gripper[:,3:6].to(torch.float32))\n",
    "gripper_open_gt = gt_gripper[:,6].to(torch.int64)\n",
    "gripper_open_loss = F.cross_entropy(gripper_logits[:,6,-2:], gripper_open_gt)\n",
    "\n",
    "pred_object = action_tokenizer.decode(object_logits, soft = True)\n",
    "assert pred_object.shape == gt_object.shape, f\"Object shape {pred_object.shape} != {gt_object.shape}\"\n",
    "object_position_loss = F.mse_loss(pred_object[:,:3], gt_object[:,:3].to(torch.float32))\n",
    "\n",
    "#Target Loss\n",
    "pred_target = action_tokenizer.decode(target_logits, soft = True)\n",
    "assert pred_target.shape == gt_target.shape, f\"Target shape {pred_target.shape} != {gt_target.shape}\"\n",
    "target_position_loss = F.mse_loss(pred_target[:,:3], gt_target[:,:3].to(torch.float32))\n",
    "\n",
    "#Stage Loss\n",
    "gt_stage = gt_stage.clone().detach()\n",
    "stage_loss = F.cross_entropy(stage_logits, gt_stage)\n",
    "\n",
    "#Action Loss\n",
    "pred_action = action_tokenizer.decode(action_logits, soft = True)\n",
    "assert pred_action.shape == gt_action.shape, f\"Action shape {pred_action.shape} != {gt_action.shape}\"\n",
    "action_position_loss = F.mse_loss(pred_action[:,:3], gt_action[:,:3].to(torch.float32))\n",
    "action_orientation_loss = action_tokenizer.angle_loss(pred_action[:,3:6], gt_action[:,3:6].to(torch.float32))\n",
    "action_open_gt = gt_action[:,6].to(torch.int64)\n",
    "action_open_loss = F.cross_entropy(action_logits[:,6,-2:], action_open_gt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/lawrence/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "step_idx, batch = next(enumerate(test_dataloader))\n",
    "\n",
    "test_loss_dict = {\n",
    "                \"nll_loss\": [],\n",
    "                \"gripper_position_loss\": [],\n",
    "                \"gripper_orientation_loss\": [],\n",
    "                \"gripper_open_loss\": [],\n",
    "                \"item_loss\": [],\n",
    "                \"object_position_loss\": [],\n",
    "                \"target_position_loss\": [],\n",
    "                \"stage_loss\": [],\n",
    "                \"action_position_loss\": [],\n",
    "                \"action_orientation_loss\": [],\n",
    "                \"action_open_loss\": [],\n",
    "            }\n",
    "with torch.no_grad(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    output: CausalLMOutputWithPast = vla(\n",
    "        input_ids=batch[\"input_ids\"].to(device_id),\n",
    "        attention_mask=batch[\"attention_mask\"].to(device_id),\n",
    "        pixel_values=batch[\"pixel_values\"].to(torch.bfloat16).to(device_id),\n",
    "        labels=batch[\"labels\"],\n",
    "    )\n",
    "    output_start_idx = vla.vision_backbone.featurizer.patch_embed.num_patches\n",
    "    loss_dict = action_tokenizer.get_loss(output, batch, output_start_idx)\n",
    "    for k, v in loss_dict.items():\n",
    "        test_loss_dict[k].append(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
